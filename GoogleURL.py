import time
import re
import os
import sys
import random
import tldextract
from colorama import init, Fore, Style
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    TimeoutException,
    NoSuchElementException,
    WebDriverException
)
import argparse
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from email.utils import formataddr

# åˆå§‹åŒ–å½©è‰²è¾“å‡º
init(autoreset=True)

# é»˜è®¤è¿‡æ»¤åˆ—è¡¨ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶æ‰©å±•ï¼‰
DEFAULT_FILTERS = ['google.com', 'googleadservices.com', 'googletagmanager.com']

# æ–‡æ¡£æ–‡ä»¶æ‰©å±•ååˆ—è¡¨
DOCUMENT_EXTS = ['.pdf', '.docx', '.doc', '.rar', '.inc', '.txt', '.sql', '.conf', '.xlsx', '.xls', '.csv', '.ppt',
                 '.pptx']

# å®šä¹‰æ¯ä¸ªå­—æ¯çš„åƒç´ è½®å»“ï¼ˆé€è¡Œç»˜åˆ¶ï¼Œä¸¥æ ¼å¯¹é½ï¼‰
LETTERS = {
    'G': [
        "  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  ",
        " â–ˆ     â–ˆ ",
        " â–ˆ     â–ˆ ",
        " â–ˆ  â–ˆâ–ˆâ–ˆ  ",
        " â–ˆ     â–ˆ ",
        " â–ˆ     â–ˆ ",
        "  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  "
    ],
    'o': [
        "  â–ˆâ–ˆâ–ˆâ–ˆ  ",
        " â–ˆ    â–ˆ ",
        " â–ˆ    â–ˆ ",
        " â–ˆ    â–ˆ ",
        " â–ˆ    â–ˆ ",
        " â–ˆ    â–ˆ ",
        "  â–ˆâ–ˆâ–ˆâ–ˆ  "
    ],
    'g': [
        "  â–ˆâ–ˆâ–ˆâ–ˆ  ",
        " â–ˆ    â–ˆ ",
        " â–ˆ    â–ˆ ",
        " â–ˆ  â–ˆâ–ˆâ–ˆ ",
        " â–ˆ    â–ˆ ",
        " â–ˆ  â–ˆ   ",
        "  â–ˆâ–ˆâ–ˆâ–ˆ  "
    ],
    'l': [
        " â–ˆ      ",
        " â–ˆ      ",
        " â–ˆ      ",
        " â–ˆ      ",
        " â–ˆ      ",
        " â–ˆ      ",
        " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  "
    ],
    'e': [
        "  â–ˆâ–ˆâ–ˆâ–ˆ  ",
        " â–ˆ    â–ˆ ",
        " â–ˆ      ",
        "  â–ˆâ–ˆâ–ˆâ–ˆ  ",
        " â–ˆ      ",
        " â–ˆ    â–ˆ ",
        "  â–ˆâ–ˆâ–ˆâ–ˆ  "
    ]
}

# å®šä¹‰ANSIé¢œè‰²ä»£ç 
COLORS = {
    'G': '\033[94m',  # è“è‰²
    'o1': '\033[91m',  # ç¬¬ä¸€ä¸ª o çº¢è‰²
    'o2': '\033[93m',  # ç¬¬äºŒä¸ª o é»„è‰²
    'g': '\033[94m',  # è“è‰²
    'l': '\033[92m',  # ç»¿è‰²
    'e': '\033[91m'  # çº¢è‰²
}


def print_banner():
    """æ‰“å°ç¨‹åºæ¨ªå¹…ï¼ˆä¿æŒåŸå§‹å›¾æ¡ˆä¸å˜ï¼‰"""
    # å­—æ¯é¡ºåº
    sequence = ['G', 'o1', 'o2', 'g', 'l', 'e']

    # é€è¡Œæ‰“å°ï¼ˆå…±7è¡Œï¼‰
    for row in range(7):
        line = ""
        for char in sequence:
            # è·å–å­—æ¯çš„è½®å»“
            if char == 'o1' or char == 'o2':
                letter = LETTERS['o'][row]
            else:
                letter = LETTERS[char][row]

            # æ·»åŠ é¢œè‰²
            line += f"{COLORS[char]}{letter}{'\033[0m'}  "

        print(line)

    print(Fore.GREEN + "=" * 60)
    print(Fore.GREEN + "  Google URL Search - v1.0")
    print(Fore.GREEN + "=" * 60)
    print(Style.RESET_ALL)


def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print(Fore.YELLOW + "[+] æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 7):
        print(Fore.RED + f"[-] è¯·ä½¿ç”¨Python 3.7æˆ–æ›´é«˜ç‰ˆæœ¬ (å½“å‰: {sys.version.split()[0]})")
        return False

    # æ£€æŸ¥ä¾èµ–åº“å®‰è£…
    required_libraries = {
        'selenium': 'pip install selenium',
        'tldextract': 'pip install tldextract',
        'colorama': 'pip install colorama'
    }
    for library, install_command in required_libraries.items():
        try:
            __import__(library)
            import importlib
            version = importlib.import_module(library).__version__
            print(Fore.GREEN + f"[âœ“] {library}å·²å®‰è£… (ç‰ˆæœ¬: {version})")
        except ImportError:
            print(Fore.RED + f"[-] æœªæ‰¾åˆ°{library}åº“ï¼Œè¯·è¿è¡Œ: {install_command}")
            return False

    return True


def find_chromedriver():
    """æŸ¥æ‰¾ChromeDriverå¯æ‰§è¡Œæ–‡ä»¶"""
    print(Fore.YELLOW + "[+] æŸ¥æ‰¾ChromeDriver...")

    # æ£€æŸ¥ç³»ç»ŸPATH
    from shutil import which
    if which("chromedriver"):
        print(Fore.GREEN + "[âœ“] åœ¨ç³»ç»ŸPATHä¸­æ‰¾åˆ°ChromeDriver")
        return which("chromedriver")

    # æ£€æŸ¥å½“å‰ç›®å½•
    current_dir = os.path.dirname(os.path.abspath(__file__))
    chromedriver_exe = os.path.join(current_dir, "chromedriver.exe" if os.name == 'nt' else "chromedriver")

    if os.path.exists(chromedriver_exe):
        print(Fore.GREEN + f"[âœ“] åœ¨å½“å‰ç›®å½•æ‰¾åˆ°ChromeDriver: {chromedriver_exe}")
        return chromedriver_exe

    print(Fore.RED + "[-] æœªæ‰¾åˆ°ChromeDriver")
    print(Fore.YELLOW + "[*] è¯·ä»https://sites.google.com/chromium.org/driver/ä¸‹è½½å¯¹åº”ç‰ˆæœ¬")
    print(Fore.YELLOW + "[*] å¹¶å°†chromedriver.exeæ”¾åœ¨è„šæœ¬åŒä¸€ç›®å½•æˆ–ç³»ç»ŸPATHä¸­")
    return None


def setup_driver(proxy=None):
    """é…ç½®å¹¶å¯åŠ¨æµè§ˆå™¨é©±åŠ¨ï¼ˆå¢å¼ºåæ£€æµ‹èƒ½åŠ›ï¼‰"""
    print(Fore.YELLOW + "[+] å‡†å¤‡å¯åŠ¨æµè§ˆå™¨...")

    # æŸ¥æ‰¾ChromeDriver
    chromedriver_path = find_chromedriver()
    if not chromedriver_path:
        raise FileNotFoundError("æœªæ‰¾åˆ°ChromeDriver")

    options = webdriver.ChromeOptions()

    # å¢å¼ºåæ£€æµ‹å‚æ•°
    options.add_argument("--start-maximized")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-notifications")
    options.add_argument("--window-size=1920,1080")

    # è®¾ç½®éšæœºUser-Agent
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
    ]
    options.add_argument(f"user-agent={random.choice(user_agents)}")

    # è®¾ç½®ä»£ç†
    if proxy:
        options.add_argument(f"--proxy-server={proxy}")
        print(Fore.YELLOW + f"[+] ä½¿ç”¨ä»£ç†: {proxy}")

    # åˆ›å»ºæµè§ˆå™¨å®ä¾‹
    try:
        service = Service(chromedriver_path)
        driver = webdriver.Chrome(service=service, options=options)
        print(Fore.GREEN + f"[âœ“] æµè§ˆå™¨å·²æˆåŠŸå¯åŠ¨")

        # æ·»åŠ é¢å¤–çš„JavaScriptéšè—è‡ªåŠ¨åŒ–ç‰¹å¾
        driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": """
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                });
                window.chrome = {
                    runtime: {},
                };
            """
        })

        return driver
    except WebDriverException as e:
        print(Fore.RED + f"[-] å¯åŠ¨æµè§ˆå™¨æ—¶å‡ºé”™: {str(e)}")
        print(Fore.RED + "[-] è¯·ç¡®ä¿ChromeDriverç‰ˆæœ¬ä¸æ‚¨çš„Chromeæµè§ˆå™¨ç‰ˆæœ¬å…¼å®¹")
        raise


def check_for_captcha(driver):
    """æ£€æŸ¥é¡µé¢æ˜¯å¦å­˜åœ¨éªŒè¯ç """
    captcha_elements = [
        '//div[@class="g-recaptcha"]',
        '//iframe[contains(@src, "recaptcha")]',
        '//input[@id="captcha"]',
        '//div[contains(text(), "éªŒè¯")]',
        '//div[contains(text(), "captcha")]',
        '//div[contains(text(), "are you a robot")]'
    ]

    for xpath in captcha_elements:
        try:
            WebDriverWait(driver, 3).until(
                EC.presence_of_element_located((By.XPATH, xpath))
            )
            print(Fore.RED + "[!] æ£€æµ‹åˆ°éªŒè¯ç ï¼")
            return True
        except TimeoutException:
            continue

    return False


def handle_captcha(driver, max_attempts=3):
    """å¤„ç†éªŒè¯ç """
    attempts = 0
    while attempts < max_attempts:
        attempts += 1
        print(Fore.YELLOW + f"[+] å°è¯•å¤„ç†éªŒè¯ç  ({attempts}/{max_attempts})...")

        # äººå·¥å¹²é¢„æ–¹å¼
        print(Fore.YELLOW + "[!] éœ€è¦äººå·¥å¹²é¢„ï¼š")
        print(Fore.YELLOW + "[!] 1. è¯·åœ¨æ‰“å¼€çš„æµè§ˆå™¨ä¸­å®ŒæˆéªŒè¯ç ")
        print(Fore.YELLOW + "[!] 2. å®ŒæˆåæŒ‰å›è½¦é”®ç»§ç»­")
        print(Fore.YELLOW + "[!] 3. å¦‚æ— æ³•å®Œæˆï¼Œè¯·æŒ‰ Ctrl+C ç»ˆæ­¢ç¨‹åº")

        # ç­‰å¾…ç”¨æˆ·è¾“å…¥
        input("[*] æŒ‰å›è½¦é”®ç»§ç»­...")

        # å†æ¬¡æ£€æŸ¥éªŒè¯ç æ˜¯å¦è¿˜å­˜åœ¨
        if not check_for_captcha(driver):
            print(Fore.GREEN + "[âœ“] éªŒè¯ç å·²æˆåŠŸå¤„ç†")
            return True

        print(Fore.RED + "[-] éªŒè¯ç ä»ç„¶å­˜åœ¨ï¼Œè¯·é‡è¯•")

    print(Fore.RED + "[!] éªŒè¯ç å¤„ç†å¤±è´¥ï¼Œè¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°")
    return False


def get_url_ext(url):
    """è·å–URLçš„æ–‡ä»¶æ‰©å±•å"""
    # å¤„ç†å¯èƒ½åŒ…å«æŸ¥è¯¢å‚æ•°çš„URL
    path = url.split('?')[0].split('#')[0]
    return os.path.splitext(path)[1].lower()


def should_filter_url(url, target_domain, filters=DEFAULT_FILTERS):
    """åˆ¤æ–­URLæ˜¯å¦åº”è¯¥è¢«è¿‡æ»¤"""
    # æ’é™¤åŒ…å«è¿‡æ»¤å…³é”®è¯çš„URL
    for filter_domain in filters:
        if filter_domain in url:
            return True

    # ç¡®ä¿URLåŒ…å«ç›®æ ‡åŸŸåï¼ˆå¯é€‰å¢å¼ºé€»è¾‘ï¼‰
    if target_domain and target_domain not in url:
        return True

    return False


def extract_urls(driver, query, max_possible_pages=100):
    """çˆ¬å–æ‰€æœ‰å¯è®¿é—®é¡µé¢ä¸­çš„URLï¼Œå¹¶åº”ç”¨è¿‡æ»¤è§„åˆ™"""
    base_domain = query.split(":")[1] if ":" in query else query
    regular_urls = set()  # æ™®é€šURL
    document_urls = {ext: set() for ext in DOCUMENT_EXTS}  # æŒ‰æ‰©å±•ååˆ†ç±»çš„æ–‡æ¡£URL
    retry_count = 0
    max_retries = 3
    timeout_count = 0
    max_timeout_count = 9  # è¿ç»­è¶…æ—¶æ¬¡æ•°ä¸Šé™
    filtered_count = 0  # è®°å½•è¿‡æ»¤æ‰çš„URLæ•°é‡

    print(Fore.YELLOW + f"[+] ä½¿ç”¨è¿‡æ»¤è§„åˆ™: {', '.join(DEFAULT_FILTERS)}")
    print(Fore.YELLOW + f"[+] æ–‡æ¡£ç±»å‹æ£€æµ‹: {', '.join(DOCUMENT_EXTS)}")

    while retry_count < max_retries:
        try:
            search_url = f"https://www.google.com/search?q={query}"
            driver.get(search_url)
            print(Fore.YELLOW + f"[+] è®¿é—®æœç´¢é¡µé¢: {search_url}")

            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            try:
                WebDriverWait(driver, 20).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href]'))
                )
                timeout_count = 0  # é¡µé¢åŠ è½½æˆåŠŸï¼Œé‡ç½®è¶…æ—¶è®¡æ•°å™¨
            except TimeoutException:
                # é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå¯èƒ½é‡åˆ°éªŒè¯ç 
                print(Fore.RED + "[-] é¡µé¢åŠ è½½è¶…æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦é‡åˆ°éªŒè¯ç ...")
                if check_for_captcha(driver):
                    if not handle_captcha(driver):
                        print(Fore.RED + "[!] éªŒè¯ç å¤„ç†å¤±è´¥ï¼Œè·³è¿‡å½“å‰åŸŸå")
                        return regular_urls, document_urls
                    else:
                        # é‡æ–°åŠ è½½é¡µé¢
                        driver.get(search_url)
                        WebDriverWait(driver, 20).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href]'))
                        )
                else:
                    print(Fore.RED + "[-] é¡µé¢åŠ è½½è¶…æ—¶ï¼Œä½†æœªæ£€æµ‹åˆ°éªŒè¯ç ")
                    timeout_count += 1
                    if timeout_count >= max_timeout_count:
                        print(Fore.YELLOW + "[*] è¿ç»­å¤šæ¬¡é¡µé¢åŠ è½½è¶…æ—¶ï¼Œåœæ­¢çˆ¬å–")
                        return regular_urls, document_urls

            current_page = 1
            has_more_pages = True

            while has_more_pages and current_page <= max_possible_pages:
                print(Fore.YELLOW + f"\n[+] æ­£åœ¨å¤„ç†ç¬¬ {current_page} é¡µ...")

                try:
                    # å°è¯•æå–é“¾æ¥
                    links = WebDriverWait(driver, 10).until(
                        EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a[href]'))
                    )

                    if not links:
                        # æ²¡æœ‰æ‰¾åˆ°é“¾æ¥ï¼Œå¯èƒ½é‡åˆ°éªŒè¯ç 
                        print(Fore.RED + "[-] æœªæ‰¾åˆ°æœç´¢ç»“æœé“¾æ¥ï¼Œæ£€æŸ¥æ˜¯å¦é‡åˆ°éªŒè¯ç ...")
                        if check_for_captcha(driver):
                            if not handle_captcha(driver):
                                print(Fore.RED + "[!] éªŒè¯ç å¤„ç†å¤±è´¥ï¼Œåœæ­¢çˆ¬å–å½“å‰åŸŸå")
                                has_more_pages = False
                                break
                            else:
                                # åˆ·æ–°é¡µé¢é‡æ–°å°è¯•
                                driver.refresh()
                                WebDriverWait(driver, 10).until(
                                    EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href]'))
                                )
                                continue
                        else:
                            print(Fore.RED + "[-] æœªæ‰¾åˆ°é“¾æ¥ï¼Œä½†æœªæ£€æµ‹åˆ°éªŒè¯ç ")
                            break

                    print(Fore.YELLOW + f"[*] æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥")

                    page_regular_urls = set()
                    page_document_urls = {ext: set() for ext in DOCUMENT_EXTS}
                    page_filtered = 0

                    for i, link in enumerate(links, 1):
                        try:
                            href = link.get_attribute('href')
                            if href and 'http' in href:
                                # åº”ç”¨è¿‡æ»¤è§„åˆ™
                                if should_filter_url(href, base_domain):
                                    page_filtered += 1
                                    continue

                                # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æ¡£æ–‡ä»¶
                                ext = get_url_ext(href)
                                if ext in DOCUMENT_EXTS:
                                    if href not in document_urls[ext]:
                                        page_document_urls[ext].add(href)
                                        print(Fore.BLUE + f"[âœ“] æ‰¾åˆ°æ–‡æ¡£URL ({ext}): {href}")
                                    continue

                                # æ™®é€šURLå¤„ç†
                                if href not in regular_urls:
                                    page_regular_urls.add(href)
                                    print(Fore.GREEN + f"[âœ“] æ‰¾åˆ°æ™®é€šURL ({i}/{len(links)}): {href}")
                        except Exception as e:
                            print(Fore.RED + f"[-] æå–é“¾æ¥æ—¶å‡ºé”™: {str(e)}")

                    # åˆå¹¶URLå¹¶å»é‡
                    new_regular_urls = page_regular_urls - regular_urls
                    regular_urls.update(new_regular_urls)

                    for ext in DOCUMENT_EXTS:
                        new_docs = page_document_urls[ext] - document_urls[ext]
                        document_urls[ext].update(new_docs)

                    filtered_count += page_filtered

                    # è®¡ç®—æ–‡æ¡£URLæ€»æ•°
                    page_doc_count = sum(len(urls) for urls in page_document_urls.values())
                    total_doc_count = sum(len(urls) for urls in document_urls.values())

                    print(
                        Fore.YELLOW + f"[*] æœ¬é¡µæ–°å¢ {len(new_regular_urls)} ä¸ªæ™®é€šURLï¼Œ{page_doc_count} ä¸ªæ–‡æ¡£URLï¼Œè¿‡æ»¤ {page_filtered} ä¸ª")
                    print(
                        Fore.YELLOW + f"[*] ç´¯è®¡: {len(regular_urls)} ä¸ªæ™®é€šURL | {total_doc_count} ä¸ªæ–‡æ¡£URL | æ€»è¿‡æ»¤: {filtered_count}")

                    # å°è¯•ç¿»é¡µ
                    try:
                        # æŸ¥æ‰¾ä¸‹ä¸€é¡µæŒ‰é’®
                        next_button = WebDriverWait(driver, 10).until(
                            EC.element_to_be_clickable((By.ID, 'pnnext'))
                        )
                        # æ»šåŠ¨åˆ°æŒ‰é’®å¹¶ç‚¹å‡»
                        driver.execute_script("arguments[0].scrollIntoView(true);", next_button)
                        time.sleep(1)
                        next_button.click()

                        # éšæœºå»¶è¿Ÿ
                        delay = 4 + random.uniform(1, 3)
                        print(Fore.YELLOW + f"[*] ç­‰å¾… {delay:.1f} ç§’ååŠ è½½ä¸‹ä¸€é¡µ...")
                        time.sleep(delay)

                        # æ£€æŸ¥ç¿»é¡µåæ˜¯å¦èƒ½æ­£å¸¸åŠ è½½å†…å®¹
                        try:
                            WebDriverWait(driver, 10).until(
                                EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href]'))
                            )
                        except TimeoutException:
                            # ç¿»é¡µåå†…å®¹æœªåŠ è½½ï¼Œå¯èƒ½é‡åˆ°éªŒè¯ç 
                            print(Fore.RED + "[-] ç¿»é¡µåå†…å®¹åŠ è½½è¶…æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦é‡åˆ°éªŒè¯ç ...")
                            if check_for_captcha(driver):
                                if not handle_captcha(driver):
                                    print(Fore.RED + "[!] éªŒè¯ç å¤„ç†å¤±è´¥ï¼Œåœæ­¢çˆ¬å–å½“å‰åŸŸå")
                                    has_more_pages = False
                                    break
                                else:
                                    # åˆ·æ–°é¡µé¢é‡æ–°å°è¯•
                                    driver.refresh()
                                    WebDriverWait(driver, 10).until(
                                        EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href]'))
                                    )
                            else:
                                print(Fore.RED + "[-] ç¿»é¡µåå†…å®¹åŠ è½½è¶…æ—¶ï¼Œä½†æœªæ£€æµ‹åˆ°éªŒè¯ç ")
                                break

                        current_page += 1

                    except (NoSuchElementException, TimeoutException):
                        # æ— ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œç»“æŸçˆ¬å–
                        print(Fore.YELLOW + "[*] æœªæ‰¾åˆ°æ›´å¤šé¡µé¢ï¼Œçˆ¬å–ç»“æŸ")
                        has_more_pages = False

                except Exception as e:
                    print(Fore.RED + f"[-] å¤„ç†é¡µé¢æ—¶å‡ºé”™: {str(e)}")
                    # æ£€æŸ¥æ˜¯å¦é‡åˆ°éªŒè¯ç 
                    if check_for_captcha(driver):
                        if not handle_captcha(driver):
                            print(Fore.RED + "[!] éªŒè¯ç å¤„ç†å¤±è´¥ï¼Œåœæ­¢çˆ¬å–å½“å‰åŸŸå")
                            has_more_pages = False
                            break
                    else:
                        print(Fore.RED + "[-] å¤„ç†é¡µé¢æ—¶å‡ºé”™ï¼Œä½†æœªæ£€æµ‹åˆ°éªŒè¯ç ")
                        has_more_pages = False
                        break

            # æ‰€æœ‰é¡µé¢å¤„ç†å®Œæˆ
            print(Fore.GREEN + f"[âœ“] å·²å®Œæˆæ‰€æœ‰å¯è®¿é—®é¡µé¢çš„çˆ¬å–ï¼ˆå…± {current_page - 1} é¡µï¼‰")
            print(Fore.YELLOW + f"[*] æ€»å…±è¿‡æ»¤æ‰ {filtered_count} ä¸ªURL")
            break

        except WebDriverException as e:
            if "invalid session id" in str(e) and retry_count < max_retries:
                print(Fore.RED + f"[-] ä¼šè¯ä¸­æ–­ï¼Œç¬¬ {retry_count + 1}/{max_retries} æ¬¡é‡è¯•...")
                retry_count += 1
                time.sleep(5)
            else:
                print(Fore.RED + f"[-] è‡´å‘½é”™è¯¯: {str(e)}")
                break

    return regular_urls, document_urls


def save_results(regular_urls, document_urls, base_domain):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    results_saved = False
    documents_saved = False
    # åˆ›å»ºresultsæ–‡ä»¶å¤¹
    results_dir = "results"
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
    # åˆ›å»ºåŸŸåå¯¹åº”çš„æ–‡ä»¶å¤¹
    domain_dir = os.path.join(results_dir, base_domain)
    if not os.path.exists(domain_dir):
        os.makedirs(domain_dir)
    # ä¿å­˜æ™®é€šURL
    if regular_urls:
        regular_file = os.path.join(domain_dir, f"Google_URLs_{base_domain}.txt")
        with open(regular_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(sorted(regular_urls)))
        print(Fore.GREEN + f"[âœ“] æ™®é€šURLä¿å­˜è‡³: {regular_file}")
        results_saved = True
    # è®¡ç®—æ–‡æ¡£URLæ€»æ•°
    total_documents = sum(len(urls) for urls in document_urls.values())
    # å¦‚æœæœ‰æ–‡æ¡£URLï¼Œåˆ›å»ºæ–‡æ¡£æ–‡ä»¶å¤¹å¹¶ä¿å­˜
    if total_documents > 0:
        documents_dir = os.path.join(domain_dir, "documents")
        if not os.path.exists(documents_dir):
            os.makedirs(documents_dir)
        # æŒ‰æ–‡ä»¶ç±»å‹ä¿å­˜æ–‡æ¡£URL
        for ext, urls in document_urls.items():
            if urls:
                doc_type_dir = os.path.join(documents_dir, ext[1:])  # å»æ‰æ‰©å±•åå‰çš„ç‚¹
                if not os.path.exists(doc_type_dir):
                    os.makedirs(doc_type_dir)
                doc_file = os.path.join(doc_type_dir, f"{base_domain}{ext}.txt")
                with open(doc_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(sorted(urls)))
                print(Fore.BLUE + f"[âœ“] {ext.upper()} æ–‡æ¡£URLä¿å­˜è‡³: {doc_file}")
                documents_saved = True
    return results_saved, documents_saved


def print_results(regular_urls, document_urls, base_domain):
    """æ‰“å°ç»“æœ"""
    if not regular_urls and sum(len(urls) for urls in document_urls.values()) == 0:
        print(Fore.RED + "\n[-] æœªæ‰¾åˆ°ä»»ä½•URLï¼Œè¯·æ£€æŸ¥æœç´¢è¯­æ³•æˆ–ç½‘ç»œ")
        return
    print(Fore.GREEN + f"\n[+] ä¸º {base_domain} æå–åˆ°çš„ç»“æœ:")
    print(Fore.GREEN + "-" * 60)
    if regular_urls:
        print(Fore.GREEN + f"[+] {len(regular_urls)} ä¸ªæ™®é€šURL:")
        for i, url in enumerate(sorted(regular_urls), 1):
            print(f"{i}. {url}")
    # è®¡ç®—æ–‡æ¡£URLæ€»æ•°
    total_documents = sum(len(urls) for urls in document_urls.values())
    if total_documents > 0:
        print(Fore.BLUE + f"\n[+] {total_documents} ä¸ªæ–‡æ¡£URL (æŒ‰ç±»å‹åˆ†ç±»):")
        for ext, urls in document_urls.items():
            if urls:
                print(Fore.BLUE + f"\n  [{ext.upper()}] ({len(urls)} ä¸ª):")
                for i, url in enumerate(sorted(urls), 1):
                    print(f"  {i}. {url}")
    print(Fore.GREEN + "-" * 60)


def send_email(sender_email, sender_password, receiver_email, subject, content):
    # åˆ›å»ºé‚®ä»¶å¯¹è±¡
    message = MIMEMultipart()
    # ä½¿ç”¨ formataddr å‡½æ•°ä¸¥æ ¼æŒ‰ç…§ RFC æ ‡å‡†æ ¼å¼åŒ– From å­—æ®µ
    sender_name = "Python é‚®ä»¶å‘é€"
    message['From'] = formataddr((str(Header(sender_name, 'utf-8')), sender_email))
    message['To'] = receiver_email  # ç›´æ¥ä½¿ç”¨é‚®ç®±åœ°å€ï¼ŒQQé‚®ç®±ä¸æ¥å— Header åŒ…è£…
    message['Subject'] = Header(subject, 'utf-8')
    # æ·»åŠ é‚®ä»¶æ­£æ–‡
    message.attach(MIMEText(content, 'plain', 'utf-8'))
    try:
        # è¿æ¥QQé‚®ç®±SMTPæœåŠ¡å™¨ï¼ˆSSLåŠ å¯†ï¼‰
        smtp_obj = smtplib.SMTP_SSL('smtp.qq.com', 465)
        smtp_obj.login(sender_email, sender_password)
        # å‘é€é‚®ä»¶
        smtp_obj.sendmail(sender_email, [receiver_email], message.as_string())
        print("é‚®ä»¶å‘é€æˆåŠŸï¼")
    except smtplib.SMTPException as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥: {e}")
    finally:
        # å…³é—­è¿æ¥
        if 'smtp_obj' in locals():
            smtp_obj.quit()


if __name__ == "__main__":
    print_banner()
    if not check_environment():
        sys.exit(1)
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='Google URL Search')
    parser.add_argument('-f', '--file', type=str, required=True, help='åŸŸåæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--proxy', type=str, default='127.0.0.1:7890', help='HTTPä»£ç†åœ°å€ (é»˜è®¤: 127.0.0.1:7890)')
    args = parser.parse_args()

    # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
    total_domains = 0
    total_regular_urls = 0
    total_document_urls = 0

    try:
        with open(args.file, 'r') as f:
            domains = [line.strip() for line in f if line.strip()]
        total_domains = len(domains)
        print(Fore.GREEN + f"[+] è¯»å–åˆ° {total_domains} ä¸ªåŸŸå")
    except Exception as e:
        print(Fore.RED + f"[-] è¯»å–åŸŸåæ–‡ä»¶å¤±è´¥: {str(e)}")
        sys.exit(1)

    driver = setup_driver(args.proxy)
    for domain in domains:
        print(Fore.CYAN + f"\n{'=' * 50}")
        print(Fore.CYAN + f"[+] å¼€å§‹çˆ¬å–åŸŸå: {domain}")
        print(Fore.CYAN + f"{'=' * 50}")
        try:
            start_time = time.time()
            query = f"site:{domain}"
            regular_urls, document_urls = extract_urls(driver, query)
            end_time = time.time()
            # è®¡ç®—æ–‡æ¡£URLæ€»æ•°
            domain_doc_count = sum(len(urls) for urls in document_urls.values())
            # æ›´æ–°å…¨å±€ç»Ÿè®¡
            total_regular_urls += len(regular_urls)
            total_document_urls += domain_doc_count

            if regular_urls or domain_doc_count > 0:
                regular_saved, docs_saved = save_results(regular_urls, document_urls, domain)
                print(Fore.GREEN + "\n[âœ“] çˆ¬å–ç»Ÿè®¡:")
                print(Fore.GREEN + f"  - çˆ¬å–æ€»URLæ•°é‡: {len(regular_urls) + domain_doc_count}")
                print(Fore.GREEN + f"  - æ™®é€šURL: {len(regular_urls)}")
                print(Fore.BLUE + f"  - æ–‡æ¡£URL: {domain_doc_count}")
                print(Fore.YELLOW + f"  - è€—æ—¶: {end_time - start_time:.2f} ç§’")
                if regular_saved:
                    print(
                        Fore.GREEN + f"  - æ™®é€šURLè·¯å¾„: {os.path.join('results', domain, f'Google_URLs_{domain}.txt')}")
                if docs_saved:
                    print(Fore.BLUE + f"  - æ–‡æ¡£URLè·¯å¾„: {os.path.join('results', domain, 'documents')}")
            else:
                print(Fore.RED + f"[-] {domain} æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆURLï¼Œä¸ç”Ÿæˆæ–‡ä»¶")
        except Exception as e:
            print(Fore.RED + f"[-] å¤„ç† {domain} å‡ºé”™: {str(e)}")

    driver.quit()
    print(Fore.GREEN + "\n[+] æ‰€æœ‰åŸŸåå¤„ç†å®Œæ¯•ï¼")

    # å‘é€æ±‡æ€»é‚®ä»¶
    email_config = {
        "sender_email": "xxx@qq.com",
        "sender_password": "xxx",
        "receiver_email": "xxx@163.com",
        "subject": "ğŸ“§ Chromeçš„URLä¿¡æ¯æ”¶é›†å·¥ä½œå·²å®Œæˆï¼",
        "content": f"""
        æ‚¨å¥½ï¼å°Šæ•¬çš„è¾‰å°é±¼å…ˆç”Ÿï¼
        å…³äºChromeçš„URLæ”¶é›†å·¥ä½œå·²å…¨é¢å®Œæˆï¼

        æœ¬æ¬¡çˆ¬å–ç»Ÿè®¡ï¼š
        - æ€»åŸŸåæ•°é‡ï¼š{total_domains}
        - æ™®é€šURLæ€»æ•°ï¼š{total_regular_urls}
        - æ–‡æ¡£URLæ€»æ•°ï¼š{total_document_urls}

        å¦‚æœä½ æ”¶åˆ°äº†è¿™å°é‚®ä»¶ï¼Œè¯´æ˜GoogleURLSearch.pyè„šæœ¬å·²è¿è¡Œå®Œæ¯•ï¼
        ç¥æ‚¨æŒ–æ´æ„‰å¿«ï¼Œå¿…å‡ºé«˜å±å“¦~~~
        GoogleFirefoxURL é‚®ä»¶åŠ©æ‰‹
        """
    }

    send_email(**email_config)
